{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPF+vHvPxeHUCtxSmwi9LOC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jprochao/Rede-neural-do-zero-DIO/blob/main/Rede_neural_do_zero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "l7E8CRs4woje"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor() #define conversão imagem\n",
        "\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) # carrega a parte do treino\n",
        "trainload = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # cria buffer dos dados\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) # carrega a validação\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)# cria buffer"
      ],
      "metadata": {
        "id": "EKAKwhaixOPv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(trainload)\n",
        "imagens, etiquetas = dataiter.next()\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "2lxFkK9ozpZ9",
        "outputId": "1d603585-26d2-4157-f14e-a78cc365ad51"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(imagens[0].shape) #verificar dimensões do tensor\n",
        "print(etiquetas[0].shape)#verificar dimensões etiqueta\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aK7KGWVN0Meh",
        "outputId": "588a2630-83b6-428c-a9e7-3201cbbea127"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Modelo(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Modelo, self).__init__()\n",
        "    self.linear1 = nn.Linear(28*28, 128)\n",
        "    self.linear2 = nn.Linear(128, 64)\n",
        "    self.linear3 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = F.relu(self.linear1(X))\n",
        "    X = F.relu(self.linear2(X))\n",
        "    X = self.linear3(X)\n",
        "    return F.log_softmax(X, dim=1)"
      ],
      "metadata": {
        "id": "5KEfSLjn6dHu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def treino(modelo, trainloader, device):\n",
        "\n",
        "  otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)\n",
        "  inicio = time()\n",
        "  \n",
        "  criterio = nn.NLLLoss()\n",
        "  EPOCHS = 10\n",
        "  modelo.train()\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    perda_acumulada = 0\n",
        "    \n",
        "    for imagens, etiquetas in trainloader:\n",
        "\n",
        "      imagens = imagens.view(imagens.shape[0], -1)\n",
        "      otimizador.zero_grad()\n",
        "\n",
        "      output = modelo(imagens.to(device))\n",
        "      perda_instantanea = criterio(output, etiquetas.to(device))\n",
        "\n",
        "      perda_instantanea.backward()\n",
        "\n",
        "      otimizador.step()\n",
        "\n",
        "      perda_acumulada += perda_instantanea.item()\n",
        "\n",
        "\n",
        "    else:\n",
        "      print(\"Epoch {} - Perda resultante: {}\".format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "  print(\"\\nTempo de treino (em minutos) = \",(time()-inicio)/60)\n"
      ],
      "metadata": {
        "id": "YFLPrLrV7ca9"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validacao(modelo, valloader, device):\n",
        "  conta_corretas, conta_todas = 0, 0\n",
        "  for imagens, etiquetas in valloader:\n",
        "    for i in range(len(etiquetas)):\n",
        "      img = imagens[i].view(1, 784)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        logps = modelo(img.to(device))\n",
        "\n",
        "      ps = torch.exp(logps)\n",
        "      probab = list(ps.cpu().numpy()[0])\n",
        "      etiqueta_pred = probab.index(max(probab))\n",
        "      etiqueta_certa = etiquetas.numpy()[i]\n",
        "      if(etiqueta_certa == etiqueta_pred):\n",
        "        conta_corretas += 1\n",
        "      conta_todas += 1\n",
        "\n",
        "    print(\"Total de imagens testadas =\", conta_todas)\n",
        "    print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*100*conta_todas))"
      ],
      "metadata": {
        "id": "sK6JFhMg9dbh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = Modelo()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So3_HGwlAJmH",
        "outputId": "4e5f05f6-b8e5-4944-e4fb-4734aa6fd121"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}